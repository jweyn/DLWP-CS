{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DLWP on Azure with Microsoft Azure Machine Learning service\n",
    "For a reference on getting started with the Microsoft Azure Machine Learning service, refer to the [Microsoft documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/).\n",
    "\n",
    "First, let's import the core AzureML Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the parameters for our model run\n",
    "Here we set the directory where the dataset of predictor/target data is stored, the name of said dataset, and the name of the model to save. Tags optionally specifies some parameters for easy reference in the list of experiment runs. The environment name is the environment to use/create on Azure ML. Set to None to use a default configuration with TensorFlow 1.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_directory = '/home/disk/wave2/jweyn/Data/Azure'\n",
    "predictor_file = 'era5/era5_2deg_3h_CS_1979-2018_z-tau-t2_500-1000_tcwv.nc'\n",
    "model_file = 'dlwp_era5_6h-3_CS48_tau-sfc1000-lsm-topo_UNET2-48-relumax'\n",
    "log_file = 'logs/era5_6h-3_CS48_tau-sfc1000-lsm-topo_UNET2-48-relumax'\n",
    "tags = {'in': 'tau-sfc-6h-3-lsm-topo', 'out': 'tau-sfc', 'arch': 'UNET2-48-relumax-T2'}\n",
    "environment_name = 'tf-1.13'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create or import a workspace\n",
    "In this example, we assume a workspace already exists, but it is easy to create a workspace on-the-fly with `Workspace.create()`. Use environment variables to load sensitive information such as `subscription_id` and authentication passwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws = Workspace.get(\n",
    "    name='dlwp-ml-scus',\n",
    "    subscription_id=os.environ.get('AZURE_SUBSCRIPTION_ID'),\n",
    "    resource_group='DLWP'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the compute cluster\n",
    "This code, adapted from the Microsoft documentation example, checks for existing compute resources in the workspace or creates them if they do not exist. We use GPU nodes, of which there are a few choices:\n",
    "- STANDARD_NC6: Tesla K80\n",
    "- STANDARD_NC6_v2: Tesla P100\n",
    "- STANDARD_NC6_v3: Tesla V100\n",
    "- STANDARD_ND6: Tesla P40\n",
    "- STANDARD_NV6: Tesla M60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "# Name of the cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"compute-NC6v3\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 2)\n",
    "\n",
    "# Set a GPU VM type\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_NC6s_v3\")\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Using existing compute target (%s)' % compute_name)\n",
    "else:\n",
    "    print('Creating compute target (%s)' % compute_name)\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy data to the compute cluster\n",
    "This optional step is needed if data hasn't yet been uploaded to a storage blob connected to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore(ws, 'cs2deg3h')\n",
    "print('Datastore name, account, container')\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "# ds.upload(src_dir=data_directory, target_path='era5', overwrite=False, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_name = 'era-CS'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionally create a user-managed environment\n",
    "\n",
    "Azure ML makes it possible to create a custom environment (e.g., customized Docker images). This is useful for getting reproducible python environments for multiple experiments. This should build a useable environment for what we want to do... if not, we supply arguments to the TensorFlow Estimator class instance below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.environment import CondaDependencies\n",
    "\n",
    "conda_pkgs = ['netCDF4', 'dask', 'xarray', 'scikit-learn']\n",
    "pip_pkgs = ['keras==2.2.4']\n",
    "\n",
    "if environment_name is not None:\n",
    "    if environment_name in Environment.list(workspace=ws).keys():\n",
    "        print('Using existing environment %s' % environment_name) \n",
    "        env = Environment.get(workspace=ws, name=environment_name)\n",
    "        env_status = 'Succeeded'\n",
    "    else:\n",
    "        print('Creating environment %s' % environment_name)\n",
    "        env = Environment(name=environment_name)\n",
    "        env.docker.enabled = True\n",
    "        env.docker.gpu_support = True\n",
    "        env.docker.base_image = \"mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04\"\n",
    "        # Add this line to mount /datadrive on a remote VM\n",
    "        # env.docker.arguments = \"--mount 'type=volume,src=/datadrive,dst=/datadrive'\"\n",
    "\n",
    "        # Add conda and pip dependencies\n",
    "        conda_dep = CondaDependencies()\n",
    "        conda_dep.add_tensorflow_pip_package(core_type='gpu', version='1.14.0')\n",
    "        for pkg in conda_pkgs:\n",
    "            conda_dep.add_conda_package(pkg)\n",
    "        for pkg in pip_pkgs:\n",
    "            conda_dep.add_pip_package(pkg)\n",
    "        env.python.conda_dependencies = conda_dep\n",
    "\n",
    "        # Register the environment\n",
    "        env.register(workspace=ws)\n",
    "\n",
    "        # Build the environment\n",
    "        build = env.build(workspace=ws)\n",
    "        env_status = build.wait_for_completion(show_output=True).status\n",
    "else:\n",
    "    env_status = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a TensorFlow estimator\n",
    "Now we create a TensorFlow estimator that will send our code to be executed on the compute target.  \n",
    "\n",
    "The first option is if the image we built earlier succeeded. If so, we use that image. If not, we use the built-in image creation options. Azure creates a Docker image the first time this is run; in the future, it can re-use existing images, including the one created automatically. We upload all of the DLWP source code files located in the parent directory of this notebook.  \n",
    "\n",
    "The script we pass to the job is `train_tf.py`, located in this directory. Details about the option parameters (and configurable settings for the specific run) can be seen/set there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--root-directory': ds.path().as_mount(),  # if using ML compute\n",
    "#    '--root-directory': '/datadrive',  # if using remote VM\n",
    "    '--predictor-file': predictor_file,\n",
    "    '--model-file': model_file,\n",
    "    '--log-directory': log_file,\n",
    "    '--temp-dir': '/mnt/tmp'\n",
    "}\n",
    "\n",
    "if env_status == 'Succeeded':\n",
    "    est_args = {'environment_definition': env}\n",
    "    print('Using environment %s' % environment_name)\n",
    "else:\n",
    "    est_args = {\n",
    "        'framework_version': '1.13',\n",
    "        'conda_packages': conda_pkgs,\n",
    "        'pip_packages': pip_pkgs,\n",
    "        'use_gpu': True\n",
    "    }\n",
    "    print('Using default AzureML TF environment')\n",
    "\n",
    "tf_est = TensorFlow(source_directory=os.path.join(os.getcwd(), os.pardir),\n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script=os.path.join(os.getcwd(), 'train_cs.py'),\n",
    "                    **est_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the experiment\n",
    "...and also print a summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run = exp.submit(config=tf_est, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the saved model\n",
    "...once the run is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run.get_status() == 'Completed':\n",
    "    ds.download('/Users/Jojo/Temp/DLWP', prefix=model_file)\n",
    "else:\n",
    "    print(\"model is in '%s' status; can't download files yet\" % run.get_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds.download('/Users/Jojo/Temp/DLWP', prefix='dlwp_era5_6h-3_CS48_tau-sfc1000-lsm-topo_UNET3-relumax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional extras\n",
    "\n",
    "#### Register a storage account\n",
    "\n",
    "This code snippet demonstrates how to register a storage account onto the ML workspace. Storage accounts can be mounted on multiple workspaces. Note that in the datastore cell above, we use this account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                        datastore_name='cs2deg3h', \n",
    "                                        container_name='cs2deg3h',\n",
    "                                        account_name='era5',\n",
    "                                        account_key='<long_key_ending_with_==>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register a remote VM as a compute target\n",
    "\n",
    "It need not even be an Azure resource. However, note that you will not be able to mount a datastore using a remote VM; instead, refer to the above code for adding Docker run arguments to mount storage on the VM to the model run's container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import RemoteCompute, ComputeTarget\n",
    "\n",
    "compute_target_name = \"compute-ND12-1\"\n",
    "attach_config = RemoteCompute.attach_configuration(address='<ip_address>',\n",
    "                                                   ssh_port=22,\n",
    "                                                   username='<user>',\n",
    "                                                   private_key_file='<path/to/key/on/this/machine>',\n",
    "                                                   private_key_passphrase='<>',\n",
    "                                                   password='<password>')\n",
    "compute = ComputeTarget.attach(ws, compute_target_name, attach_config)\n",
    "status = compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just list environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "envs = Environment.list(workspace=ws)\n",
    "\n",
    "for e in envs.keys():\n",
    "    if 'gpu' in e.lower():\n",
    "        print(\"Name\", e)\n",
    "        print(\"packages\", envs[e].python.conda_dependencies.serialize_to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
